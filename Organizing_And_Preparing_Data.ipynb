{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7027e643-8167-42aa-836b-1caace1f581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ba7ffd-bedf-44d8-871b-b227bfbe0337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b6c3b1-ba3a-4a12-8b57-4c8c3200946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_train_data_dir_path=os.path.join(\"Data\",\"cifar10\",\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7354d3d-e69b-4ac0-9f42-be04c716b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_config={\n",
    "    \"class1\":[\"airplane\",\"automobile\",\"ship\",\"truck\"],\n",
    "    \"class2\":[\"cat\",\"deer\",\"dog\",\"horse\"],\n",
    "    \"class3\":[\"bird\",\"frog\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bcda68f-a86f-48de-8c01-f2cb9727f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data_dir_path=os.path.join(\"Data\",\"cifar_train_data_new\")\n",
    "os.makedirs(new_train_data_dir_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e80fc10-807b-46f2-9b84-645074a848ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_dir=os.path.join(new_train_data_dir_path,\"class1\")\n",
    "class2_dir=os.path.join(new_train_data_dir_path,\"class2\")\n",
    "class3_dir=os.path.join(new_train_data_dir_path,\"class3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b136f19-1da7-495d-85dd-0b4437b49efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(class1_dir,exist_ok=True)\n",
    "os.makedirs(class2_dir,exist_ok=True)\n",
    "os.makedirs(class3_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "691136fe-950c-4ea9-a317-74a039f304fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_type in os.listdir(old_train_data_dir_path):\n",
    "   \n",
    "    old_dir=os.path.join(old_train_data_dir_path,img_type)\n",
    "    \n",
    "    if img_type in classes_config[\"class1\"]:\n",
    "        new_dir=os.path.join(class1_dir,img_type)\n",
    "        shutil.copytree(old_dir,new_dir,dirs_exist_ok=True)\n",
    "        \n",
    "    elif img_type in classes_config[\"class2\"]:\n",
    "        new_dir=os.path.join(class2_dir,img_type)\n",
    "        shutil.copytree(old_dir,new_dir,dirs_exist_ok=True)\n",
    "        \n",
    "    elif img_type in classes_config[\"class3\"]:\n",
    "        new_dir=os.path.join(class3_dir,img_type)\n",
    "        shutil.copytree(old_dir,new_dir,dirs_exist_ok=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d55e035f-d5c1-4af2-93fd-a20a5f654256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/cifar_train_data_new'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data_dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb40ff8-7d9c-4a99-88b6-c7743d8634ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class3', 'class1', 'class2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(new_train_data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea9b76ae-2ac3-4ec8-8924-0c8c693a4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepaths(root_dir):\n",
    "    dir_level1=[os.path.join(root_dir,path) for path in os.listdir(root_dir)]\n",
    "    dir_level2=[os.path.join(dir1,dir2) for dir1 in dir_level1 for dir2 in os.listdir(dir1)]\n",
    "    filepaths=[os.path.join(dir2,path) for dir2 in dir_level2 for path in os.listdir(dir2)]\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82afd9f1-8cee-4bab-8bbd-d343a4408df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 04:06:34.786914: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-23 04:06:34.796911: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740263794.812204    6543 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740263794.816481    6543 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-23 04:06:34.829724: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41e60f90-709f-4b82-a5f1-cd78eb89fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tokenizer=Tokenizer()\n",
    "class_tokenizer.fit_on_texts(list(classes_config.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8f952f4-9e2d-431e-8468-bb37761dea63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class1': 1, 'class2': 2, 'class3': 3}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fc134bd-5f0a-4778-bad0-5007300ca3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_tokenizer=Tokenizer()\n",
    "class1_tokenizer.fit_on_texts(list(classes_config[\"class1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f61cf5c-59e9-4163-b2e8-317800140920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 1, 'automobile': 2, 'ship': 3, 'truck': 4}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d34c2cfa-d704-4f17-ae44-b8a71aa465bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 1, 'deer': 2, 'dog': 3, 'horse': 4}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2_tokenizer=Tokenizer()\n",
    "class2_tokenizer.fit_on_texts(list(classes_config[\"class2\"]))\n",
    "class2_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63034643-9dfa-4a72-999a-e32179ebaccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bird': 1, 'frog': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class3_tokenizer=Tokenizer()\n",
    "class3_tokenizer.fit_on_texts(list(classes_config[\"class3\"]))\n",
    "class3_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11f991bb-75a4-4f97-84e6-4032a70a008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e67df44c-5d0c-48f2-9cf4-1a37744146bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_class_number=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ffde7dc-23ca-4be3-8a7c-b4bf7de05e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tokenizers={\n",
    "    \"class_tokenizer\":class_tokenizer.word_index,\n",
    "    \"class1_tokenizer\":class1_tokenizer.word_index,\n",
    "    \"class2_tokenizer\":class2_tokenizer.word_index,\n",
    "    \"class3_tokenizer\":class3_tokenizer.word_index,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0be13c76-47e7-4937-97cf-c4e390409c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97444fed-a044-40df-9019-71225d047431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d29dfee-b884-451e-b079-ba6469fce421",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_subclass_in_class=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "338cea77-d163-42b0-bfa2-9f0dfd06add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=[256,256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77e4096a-cf70-484d-bd0a-a84b016f9d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths=get_filepaths(new_train_data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24590fc8-5136-47a2-b084-a9b70ead6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(filepath,max_num_subclass=4,label_tokenizers=label_tokenizers):\n",
    "     #Load Image\n",
    "    img=tf.io.read_file(filepath)\n",
    "    img=tf.io.decode_jpeg(img,channels=3)\n",
    "    img=tf.image.resize(img,img_size)\n",
    "    img/=255.0\n",
    "   \n",
    "    \n",
    "    # Labels:\n",
    "    class_tokenizer=label_tokenizers[\"class_tokenizer\"]\n",
    "    class_name=filepath.split(\"/\")[-3]\n",
    "    sub_class=filepath.split(\"/\")[-2]\n",
    "\n",
    "    # Label1:\n",
    "    label1=class_tokenizer[class_name]-1\n",
    "    label1=to_categorical(label1,len(class_tokenizer))\n",
    "    label1=tf.cast(label1,dtype=tf.float32)\n",
    "    \n",
    "    # Label2\n",
    "    sub_class_tokenizer=label_tokenizers[f\"{class_name}_tokenizer\"]\n",
    "    label2=sub_class_tokenizer[sub_class]-1\n",
    "    label2=to_categorical(label2,len(sub_class_tokenizer))\n",
    "    label2=pad_sequences([label2],maxlen=max_num_subclass,padding=\"post\")[0]\n",
    "    label2=tf.cast(label2,dtype=tf.float32)\n",
    "\n",
    "    image_bytes=tf.io.serialize_tensor(img).numpy()\n",
    "    label1_bytes=tf.io.serialize_tensor(label1).numpy()\n",
    "    label2_bytes=tf.io.serialize_tensor(label2).numpy()\n",
    "\n",
    "    feature={\n",
    "        \"image\":tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_bytes])),\n",
    "        \"label1\":tf.train.Feature(bytes_list=tf.train.BytesList(value=[label1_bytes])),\n",
    "        \"label2\":tf.train.Feature(bytes_list=tf.train.BytesList(value=[label2_bytes]))\n",
    "    }\n",
    "\n",
    "    record=tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return record\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d669b91f-8f17-4644-baba-16d1059045f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths=get_filepaths(new_train_data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eca889cd-d211-4536-8da6-d59e4b6439c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_record_path=os.path.join(\".\",\"Data\",\"train_data.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eacdcb33-6f72-4343-93e6-d8059c2dc72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Data/train_data.tfrecord'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_record_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3d2c5d1-69cc-4da6-9c92-f96e1ccc1346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 04:06:37.135905: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Records written...\n",
      "2000 Records written...\n",
      "3000 Records written...\n",
      "4000 Records written...\n",
      "5000 Records written...\n",
      "6000 Records written...\n",
      "7000 Records written...\n",
      "8000 Records written...\n",
      "9000 Records written...\n",
      "10000 Records written...\n",
      "11000 Records written...\n",
      "12000 Records written...\n",
      "13000 Records written...\n",
      "14000 Records written...\n",
      "15000 Records written...\n",
      "16000 Records written...\n",
      "17000 Records written...\n",
      "18000 Records written...\n",
      "19000 Records written...\n",
      "20000 Records written...\n",
      "21000 Records written...\n",
      "22000 Records written...\n",
      "23000 Records written...\n",
      "24000 Records written...\n",
      "25000 Records written...\n",
      "26000 Records written...\n",
      "27000 Records written...\n",
      "28000 Records written...\n",
      "29000 Records written...\n",
      "30000 Records written...\n",
      "31000 Records written...\n",
      "32000 Records written...\n",
      "33000 Records written...\n",
      "34000 Records written...\n",
      "35000 Records written...\n",
      "36000 Records written...\n",
      "37000 Records written...\n",
      "38000 Records written...\n",
      "39000 Records written...\n",
      "40000 Records written...\n",
      "41000 Records written...\n",
      "42000 Records written...\n",
      "43000 Records written...\n",
      "44000 Records written...\n",
      "45000 Records written...\n",
      "46000 Records written...\n",
      "47000 Records written...\n",
      "48000 Records written...\n",
      "49000 Records written...\n",
      "50000 Records written...\n"
     ]
    }
   ],
   "source": [
    "with tf.io.TFRecordWriter(tf_record_path) as writer:\n",
    "    for ind,path in enumerate(filepaths):\n",
    "        tf_example=preprocess_image(path)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "        \n",
    "        if (ind+1)%1000==0:\n",
    "            print(f\"{ind+1} Records written...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c64986e-8f3f-4395-bd9d-4550842079fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tf_record(example):\n",
    "    feature_description={\n",
    "        \"image\":tf.io.FixedLenFeature([],tf.string),\n",
    "        \"label1\":tf.io.FixedLenFeature([],tf.string),\n",
    "        \"label2\":tf.io.FixedLenFeature([],tf.string)\n",
    "    }\n",
    "    \n",
    "    example=tf.io.parse_single_example(example,feature_description)\n",
    "    \n",
    "    image=tf.io.parse_tensor(example[\"image\"],out_type=tf.float32)\n",
    "    label1=tf.io.parse_tensor(example[\"label1\"],out_type=tf.float32)\n",
    "    label2=tf.io.parse_tensor(example[\"label2\"],out_type=tf.float32)\n",
    "    \n",
    "    return image,(label1,label2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a7f54a9-21e8-45fc-96ad-751b7d3bec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.TFRecordDataset(tf_record_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4612c9c-10e6-4aed-b754-f7fd8ee0514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.map(parse_tf_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70d1c1c0-0f65-442a-9216-2c470e381d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8083c69e-e9d0-4a5a-93ab-f49456750792",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.shuffle(buffer_size=1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d190acb0-6e37-4a74-95c3-15f3d2a5cf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 04:09:34.631302: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:370] TFRecordDataset `buffer_size` is unspecified, default to 262144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMg:[[[0.38431373 0.38431373 0.4       ]\n",
      "  [0.38431373 0.38431373 0.4       ]\n",
      "  [0.38431373 0.38431373 0.4       ]\n",
      "  ...\n",
      "  [0.74509805 0.7294118  0.7411765 ]\n",
      "  [0.74509805 0.7294118  0.7411765 ]\n",
      "  [0.74509805 0.7294118  0.7411765 ]]\n",
      "\n",
      " [[0.38431373 0.38431373 0.4       ]\n",
      "  [0.38431373 0.38431373 0.4       ]\n",
      "  [0.38431373 0.38431373 0.4       ]\n",
      "  ...\n",
      "  [0.74509805 0.7294118  0.7411765 ]\n",
      "  [0.74509805 0.7294118  0.7411765 ]\n",
      "  [0.74509805 0.7294118  0.7411765 ]]\n",
      "\n",
      " [[0.38431373 0.38431373 0.4       ]\n",
      "  [0.38431373 0.38431373 0.4       ]\n",
      "  [0.38431373 0.38431373 0.4       ]\n",
      "  ...\n",
      "  [0.74509805 0.7294118  0.7411765 ]\n",
      "  [0.74509805 0.7294118  0.7411765 ]\n",
      "  [0.74509805 0.7294118  0.7411765 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.3137255  0.31764707 0.29803923]\n",
      "  [0.3137255  0.31764707 0.29803923]\n",
      "  [0.3137255  0.31764707 0.29803923]\n",
      "  ...\n",
      "  [0.49803922 0.5019608  0.4862745 ]\n",
      "  [0.49803922 0.5019608  0.4862745 ]\n",
      "  [0.49803922 0.5019608  0.4862745 ]]\n",
      "\n",
      " [[0.3137255  0.31764707 0.29803923]\n",
      "  [0.3137255  0.31764707 0.29803923]\n",
      "  [0.3137255  0.31764707 0.29803923]\n",
      "  ...\n",
      "  [0.49803922 0.5019608  0.4862745 ]\n",
      "  [0.49803922 0.5019608  0.4862745 ]\n",
      "  [0.49803922 0.5019608  0.4862745 ]]\n",
      "\n",
      " [[0.3137255  0.31764707 0.29803923]\n",
      "  [0.3137255  0.31764707 0.29803923]\n",
      "  [0.3137255  0.31764707 0.29803923]\n",
      "  ...\n",
      "  [0.49803922 0.5019608  0.4862745 ]\n",
      "  [0.49803922 0.5019608  0.4862745 ]\n",
      "  [0.49803922 0.5019608  0.4862745 ]]]\n",
      "label1:[0. 0. 1.]\n",
      "label2:[1. 0. 0. 0.]\n",
      "(256, 256, 3) (3,) (4,)\n"
     ]
    }
   ],
   "source": [
    "for img,label in dataset:\n",
    "    img=img[0]\n",
    "    label1=label[0][0]\n",
    "    label2=label[1][0]\n",
    "    print(f\"IMg:{img}\")\n",
    "    print(f\"label1:{label1}\")\n",
    "    print(f\"label2:{label2}\")\n",
    "    print(img.shape,label1.shape,label2.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe7e235-242e-40f1-bbf5-d0d6c8c92273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
