{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4316ab3-6884-46b8-b06c-91f638cf1e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 20:35:22.945904: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-26 20:35:23.107088: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737903923.163750 1531652 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737903923.181035 1531652 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-26 20:35:23.335455: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21589ba2-50ef-4974-b696-7ab7e10ce5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "classes_config={\n",
    "    0:3,\n",
    "    1:4,\n",
    "    2:2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68be706-8aac-434f-88ce-dd18048656ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_config=[\n",
    "    {\n",
    "        'filters':16,\n",
    "        'kernel_size':(3,3),\n",
    "        'activation':\"relu\",\n",
    "        'kernel_initializer':\"he_uniform\"\n",
    "    },\n",
    "     {\n",
    "        'filters':32,\n",
    "        'kernel_size':(5,5),\n",
    "        'activation':\"relu\",\n",
    "        'kernel_initializer':\"he_uniform\"\n",
    "    }\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d6a85e-e96b-4d76-a6b0-aba9f2120126",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer_config=[\n",
    "    {\n",
    "        'units':256,\n",
    "        'activation':\"relu\",\n",
    "        'kernel_initializer':\"he_uniform\"\n",
    "    },\n",
    "    {\n",
    "        'units':32,\n",
    "        'activation':\"relu\",\n",
    "        'kernel_initializer':\"he_uniform\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da40819c-0a06-4c55-acff-4e602ebad129",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_config={\n",
    "    'activation':\"softmax\",\n",
    "    'kernel_initializer':\"glorot_uniform\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04fd8f89-d61d-435f-9190-409961789436",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_dcn_layers_config={\n",
    "    \"ConvolutionLayers\":conv_layer_config,\n",
    "    \"DenseLayers\":dense_layer_config,\n",
    "    \"LastLayer\":last_layer_config\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11f401aa-b157-49e1-bbd7-a5b0c436e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_convolution_layer import DynamiConvolutionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ca323c-252f-42ff-9382-7ae2237fe4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=Input(shape=(1024,1024,3),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6dd309d-de2a-40aa-a1d1-c09271f8a7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 20:35:25.587065: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/home/amartya/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:1381: UserWarning: Layer 'dynami_convolution_layer' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''Exception encountered when calling InputSeparationLayer.call().\n",
      "\n",
      "\u001b[1min user code:\n",
      "\n",
      "    File \"/media/amartya/New Volume/Projects/Dynamic Convolution Networks/input_separation_layer.py\", line 24, in call  *\n",
      "        input_config[cls]=tf.reshape(ind,-1)\n",
      "\n",
      "    ValueError: Shape must be rank 1 but is rank 0 for '{{node cond/Reshape}} = Reshape[T=DT_INT64, Tshape=DT_INT32](cond/Reshape/Where, cond/Reshape/shape)' with input shapes: [?,2], [].\n",
      "\u001b[0m\n",
      "\n",
      "Arguments received by InputSeparationLayer.call():\n",
      "  • predictions=tf.Tensor(shape=(None, 3), dtype=float32)''\n",
      "  warnings.warn(\n",
      "/home/amartya/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'dynami_convolution_layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling DynamiConvolutionLayer.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'dynami_convolution_layer' (of type DynamiConvolutionLayer). Either the `DynamiConvolutionLayer.call()` method is incorrect, or you need to implement the `DynamiConvolutionLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling InputSeparationLayer.call().\n\n\u001b[1min user code:\n\n    File \"/media/amartya/New Volume/Projects/Dynamic Convolution Networks/input_separation_layer.py\", line 24, in call  *\n        input_config[cls]=tf.reshape(ind,-1)\n\n    ValueError: Shape must be rank 1 but is rank 0 for '{{node cond/Reshape}} = Reshape[T=DT_INT64, Tshape=DT_INT32](cond/Reshape/Where, cond/Reshape/shape)' with input shapes: [?,2], [].\n\u001b[0m\n\nArguments received by InputSeparationLayer.call():\n  • predictions=tf.Tensor(shape=(None, 3), dtype=float32)\u001b[0m\n\nArguments received by DynamiConvolutionLayer.call():\n  • args=('<KerasTensor shape=(None, 1024, 1024, 3), dtype=float32, sparse=False, name=keras_tensor>',)\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_class,pred_sub_class\u001b[38;5;241m=\u001b[39m\u001b[43mDynamiConvolutionLayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dcn_layers_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dcn_layers_config\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/media/amartya/New Volume/Projects/Dynamic Convolution Networks/dynamic_convolution_layer.py:74\u001b[0m, in \u001b[0;36mDynamiConvolutionLayer.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m,inputs):\n\u001b[1;32m     73\u001b[0m     inp2,pred\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_dcn_layer(inputs)\n\u001b[0;32m---> 74\u001b[0m     input_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_separation_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_driven_conv_layer_decider(inp2,input_config)\n\u001b[1;32m     76\u001b[0m     final_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombined_output_layer(out,input_config)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileuof1qcq4.py:39\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, predictions)\u001b[0m\n\u001b[1;32m     37\u001b[0m ind \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mind\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcls\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileuof1qcq4.py:36\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.loop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body\u001b[39m():\n\u001b[1;32m     35\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mld(input_config)[ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mcls\u001b[39m)] \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreshape, (ag__\u001b[38;5;241m.\u001b[39mld(ind), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 36\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_config[cls]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileuof1qcq4.py:35\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.loop_body.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body\u001b[39m():\n\u001b[0;32m---> 35\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mld(input_config)[ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mcls\u001b[39m)] \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling DynamiConvolutionLayer.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'dynami_convolution_layer' (of type DynamiConvolutionLayer). Either the `DynamiConvolutionLayer.call()` method is incorrect, or you need to implement the `DynamiConvolutionLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling InputSeparationLayer.call().\n\n\u001b[1min user code:\n\n    File \"/media/amartya/New Volume/Projects/Dynamic Convolution Networks/input_separation_layer.py\", line 24, in call  *\n        input_config[cls]=tf.reshape(ind,-1)\n\n    ValueError: Shape must be rank 1 but is rank 0 for '{{node cond/Reshape}} = Reshape[T=DT_INT64, Tshape=DT_INT32](cond/Reshape/Where, cond/Reshape/shape)' with input shapes: [?,2], [].\n\u001b[0m\n\nArguments received by InputSeparationLayer.call():\n  • predictions=tf.Tensor(shape=(None, 3), dtype=float32)\u001b[0m\n\nArguments received by DynamiConvolutionLayer.call():\n  • args=('<KerasTensor shape=(None, 1024, 1024, 3), dtype=float32, sparse=False, name=keras_tensor>',)\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "pred_class,pred_sub_class=DynamiConvolutionLayer(\n",
    "    batch_size=batch_size,\n",
    "    classes_config=classes_config,\n",
    "    pre_dcn_layers_config=pre_dcn_layers_config\n",
    ")(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a032f-0836-414f-93b6-911260fa769f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
